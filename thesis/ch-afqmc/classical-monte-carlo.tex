\section{Monte Carlo Method in Classical  Statistical Physics}
\label{sec:classical_mc}

Monte Carlo methods form the largest and arguably most useful class of numerical methods used to approach statistical physics problems.
Statistical physics often deals with computing quantities that describe the behavior of condensed matter systems.
The main difficulty one faces when doing so has to do with the collective nature of these systems.
Many identical components comprise them, and while the equations that govern the behavior of the whole may be easy to write down, their solution is in general a remarkably laborious mathematical problem.
It is both the sheer number of equations and the coupling between them that deems the task of finding an exact solution either very tough or even impossible.
Concomitantly, the exponentially large number of possible configurations of the typical condensed matter system can be daunting.
Thus, it is rather striking that we are able to describe a system that is governed by a macroscopically large number of equations in terms of only a few variables.
The loss of information in doing so is only apparent.
The statistical description is so effective because most of the possible states of the system are extremely improbable when compared to the relevant very narrow part of configuration space.
The success of the field is largely attributed to the averaging out that naturally occurs when measuring a property of a macroscopic system.
%Since analytical solutions are more often than not hopeless, these problems are solved numerically.
%Numerical results give valuable information lying between theory and experiment, and connecting them.
%It is not even clear whether an analytical solution would be of any use in many cases, and a statistical treatment often allows us to study more effectively the key properties of a system.
%Numerically, this is done using Monte Carlo.

Suppose you try to sample uniformly from the probability distribution of all possible configurations of one of the aforementioned systems.
Chances are your algorithm will not end before the Universe does.
This is the computational complexity hurdle.
A related issue is that of finite size effects.
We are far from being able to simulate a macroscopically sized system. 
At best we can simulate a system that has only a minuscule fraction of the size of a real system.
Amazingly there are techniques that allow us to efficiently extract information out of relatively small scale simulations.
Nonetheless, increasing the system size systematically improves the reliability of a simulation.
Thus, it is important to design efficient algorithms to probe larger systems in a fixed computer time frame.

The law of large numbers affords an approximation to integrals which can be written as an expectation of a random variable. Upon drawing enough independent samples from the corresponding distribution, the sample mean gets arbitrarily close to the integral at stake.
\begin{equation}\label{eq:int_mean}
\mathbb{E} [f(X)] = \int dx f(x) p(x),
\end{equation}
where $p(x)$ is the distribution of $X$. 

We could simply draw $M$ independent and identically distributed samples $x_{1,...M}$ from $p(x)$ and approximate the integral as
$
\frac{1}{M} \sum_{k=1}^M f (x_k) , 
$
 which in most cases converges to the desired expectation, as long as $M$ is large enough. How large?
\begin{equation}\label{eq:variance}
\text{Var}\bigg( \frac{1}{M} \sum_{k=1}^M f(x_k) \bigg) = \frac{1}{M} \text{Var}\bigg( f(x_1) \bigg) \propto \mathcal{O}\bigg(\frac{1}{M}\bigg)
\end{equation}

Thus, the estimation error of the mean is of order $\mathcal{O}(\frac{1}{\sqrt{M}})$, as long as $\text{Var}\big( f(x_1) \big) \sim 1$. This condition can be achieved by using importance sampling, a variance reduction technique we will shortly discuss.

But how do we sample from an arbitrary distribution $p(X)$? The idea is to start by making an educated choice of a Markov Chain with the prescribed stationary distribution, $p(X)$, from which we desire to sample from. After a sufficiently high number of steps, a Markov Chain Monte Carlo (MCMC) algorithm starts to generate samples from the target distribution. Imposing some conditions on this Markov Chain, namely that it should be irreducible, aperiodic and positive recurrent, the ergodic theorem guarantees that the empirical measures of the aforementioned sampler approach the target stationary distribution. Another important condition to impose on this Markov Chain is detailed balance. Let the transition matrix be $\bm P = [P_{\mu \rightarrow \nu}]$, and the state space $\Omega$ be $\{\pi_\mu | \mu=1, ..., |\Omega| \}$, where $|\Omega|$ is the total number of possible states. Then, the condition of detailed balance is defined for all $\mu, \nu$ as
\begin{equation}\label{eq:detBal}
\pi_\mu P_{\mu \rightarrow \nu} = P_{\nu \rightarrow \mu} \pi_\nu
\end{equation}

Consider a system in state $\mu$ that makes transitions to state $\nu$ at a rate $R_{\mu \rightarrow  \nu}$ (that specifies the system's dynamics) and vice-versa.
The probability that a system is in state $\mu$ at time $t$, $p_\mu (t)$, such that $\sum_\mu p_\mu (t) = 1$, is given by the master equation(s):
\begin{equation}\label{eq:master}
\frac{d p_\mu}{dt} = \sum_\nu \big[ p_\nu (t) R_{\nu \rightarrow \mu} - p_\mu (t) R_{\mu \rightarrow \nu} \big] \quad \forall \mu \in \Omega
\end{equation}

For a physical system, the equilibrium occupation probabilities at finite temperature $T$ follow the Boltzmann distribution.
\begin{equation}
\pi_\mu = \lim_{t \rightarrow \infty} p_\mu (t) = \frac{1}{Z} e^{ - E_\mu / k_B T} ,
\end{equation}
where $E_\mu$ is the energy of state $\mu$, $k_B$ is Boltzmann's constant, and $Z$ is the partition function. From the latter we can extract thermodynamic observables (expectations of physical quantities $\left\langle Q \right\rangle$), and response functions (in terms of their variance $\sigma_Q^{\,\, 2}$).

Imposing the condition of stationarity on Eq.(\ref{eq:master}), $d_t p_\mu = 0$ , and noting that $ P_{\mu\rightarrow \nu} = R_{\mu\rightarrow \nu}  dt$, we obtain the equilibrium condition
\begin{equation}\label{eq:equilibrium}
\sum_\nu \pi_\mu P_{\mu \rightarrow \nu} = \sum_\nu P_{\nu \rightarrow \mu} \pi_\nu \iff \pi_\mu \sum_\nu P_{\mu \rightarrow \nu} = \sum_\nu P_{\nu \rightarrow \mu} \pi_\nu \iff \pi_\mu = \sum_\nu P_{\nu \rightarrow \mu} \pi_\nu
\end{equation}

This condition is enough to ensure the convergence to an equilibrium of the Markov dynamics.
However, it does not guarantee that the equilibrium distribution is our desired one, $\bm \pi ( \infty)$.
In fact, the probability of a state evolves according to
\begin{equation}
\pi_\nu ( t + 1 ) = \sum_\mu P_{\mu\rightarrow\nu}  \pi_\mu ( t ) \iff \bm \pi ( t + 1 ) = \bm P \bm \pi ( t )
\end{equation}

The stationary distribution of a Markov chain obeys
\begin{equation}
\bm \pi ( \infty ) = \bm P \bm \pi ( \infty ) ,
\end{equation}
however, condition (\ref{eq:equilibrium}) also allows  for limit cycles of length $n$, where $\bm \pi$ rotates around a number of configurations: $
\bm \pi ( \infty ) = \bm P^n \bm \pi ( \infty ) ,
$
 where $\bm P^n$ is the n-th power of $\bm P$.
Detailed balance is a stronger requirement than the equilibrium condition, which eliminates limit cycles, thus ensuring that our sampler draws configurations from the desired distribution.
Intuitively, detailed balance corresponds to incorporating time-reversal symmetry in a simulation, and translates into the following constraint on the Markov transition probabilities:
\begin{equation}\label{eq:markovCondition}
\frac{P_{\mu\rightarrow\nu}}{P_{\nu\rightarrow\mu}} = \frac{\pi_\nu}{\pi_\mu} = e^{-\beta ( E_\nu - E_\mu ) }
\end{equation}

Crucially, Monte Carlo methods employ \emph{importance sampling}.
It turns out that we can improve upon our estimate of $\mathbb{E} [f(X)]$ by reducing the variance of the estimator. If we introduce a separate distribution $q(x)$, and define a weight function as $w(x) = p(x)/ q(x)$, we can rewrite equation (\ref{eq:int_mean}):
\begin{equation}
\mathbb{E} [f(X)] = \int dx f(x) q(x) w(x) = \mathbb{E} [f(Y) w(Y)],
\end{equation}
with $Y \sim q$, i.e. the random variable $Y$ follows the distribution $q(Y)$.
It appears as though we didn't gain anything. However, by choosing $q$ wisely, we can actually reduce the variance we computed in Eq.(\ref{eq:variance}):
\begin{equation}
\text{Var}\bigg( \frac{1}{M} \sum_{k=1}^M f(y_k) w(y_k) \bigg) = \frac{1}{M} \text{Var}\bigg( f(y_1) w(y_1) \bigg)
\end{equation}

Since we did not make any assumptions about $q(Y)$, it may be chosen so as to minimize the variance, hence the error of the Monte Carlo estimator, improving the approximation of the expectation. However, note that the error remains proportional to $\frac{1}{\sqrt{M}}$.
In practice, we devise a method to select the portion of state space which contains states contributing more significantly to the average.
This procedure ensures that $\text{Var}\big( f(y_1) w(y_1) \big) \sim 1$, improving the efficiency of our sampler.
The choice of the weight function translates to the averaging process by changing the estimator.
Explicitly computing averages is only tractable for very small systems.
In practice, we choose a subset of states $\{\mu_1, \mu_2, ..., \mu_M \} $, estimating
\begin{equation}
\left\langle Q \right\rangle = \frac{ \sum_\mu Q_\mu e^{-\beta E_\mu} }{ \sum_\mu e^{-\beta E_\mu}} \quad \text{as} \quad
Q_M = \frac{ \sum_{i=1}^M Q_{\mu_i} \pi_{\mu_i}^{-1} e^{ -\beta E_{\mu_i} } }{ \sum_{j=1}^M \pi_{\mu_j}^{-1} e^{ -\beta E_{\mu_j} }  }
\end{equation}

The estimate improves as $N$ increases, and when $N\rightarrow \infty$, $Q_M \rightarrow \left\langle Q \right\rangle$.
The accuracy of the estimator depends on the choice of the probabilities $\bm \pi$, which is related to the aforementioned variance.
For example, if $\bm \pi$ corresponds to the uniform distribution, i.e. $\pi_\mu = \frac{1}{| \Omega |} \forall \mu \in \Omega$, we have
\begin{equation}
Q_M = \frac{ \sum_{i=1}^M Q_{\mu_i} e^{ -\beta E_{\mu_i} } }{ \sum_{j=1}^M e^{ -\beta E_{\mu_j} }  } ,
\end{equation}
which turns out to be a poor choice since most of the visited states contribute negligibly to the average, leading to an inaccurate estimate.
The sum is dominated by a small subset of states, which we would like to access.
The idea of the Quantum (Classical) Monte Carlo method is to simulate the random quantum (thermal) fluctuations of a system, as it oscillates between states in a given time frame \cite{newman_monte_1999}. Instead of visiting these states uniformly, the most relevant part of the phase space is sampled more frequently, overcoming the seemingly exponential complexity of computing a sample mean numerically.
Even though only a small fraction of the system's states are sampled, we then obtain an accurate estimate of physical quantities of interest, namely energy, and correlation functions. This is implemented via a proposal-acceptance scheme.

To exploit the freedom given by condition (\ref{eq:markovCondition}), we note that we can always introduce a non-zero \say{stay-at-home} probability $P_{\mu \rightarrow \mu} \in [0, 1] $.
Regardless of its value, detailed balance is satisfied.
Similarly, any adjustment in $P_{\mu\rightarrow \nu}$ must be compensated by changing $P_{\nu\rightarrow \mu}$ to preserve their ratio.
Break the transition probability into a selection probability and an acceptance ratio, respectively:
\begin{equation}
\frac{P_{\mu\rightarrow\nu}}{P_{\nu\rightarrow\mu}}= \frac{S_{ \mu\rightarrow\nu} A_{\mu\rightarrow\nu}}{S_{ \nu\rightarrow\mu} A_{\nu\rightarrow\mu}}
\end{equation}

The Markov process now consists of generating a chain of states according to $S_{ \mu\rightarrow\nu}$, which are then accepted or rejected depending on $A_{\mu\rightarrow\nu}$.
Since we want to make the algorithm as efficient as possible, we want to make the acceptance ratio as close to one as possible to avoid useless steps.	
The most common way to do this is to fix the largest of them to one, and adjust the other accordingly.
The acceptance ratio will be close to one more often if $S_{ \mu\rightarrow\nu}$ includes most of the dependence of $P_{\mu\rightarrow\nu}$ on the characteristics of the states $\mu, \nu$.
Ideally, states would always be selected with the correct transition probability, and the acceptance ratio would be fixed to unity.
Good algorithms approach this situation, and much effort has been directed at optimizing them to do so.
By far, the most common sampling scheme choice is the Metropolis-Hastings algorithm, which we now  describe.

We select the transition probability to be uniform, and impose detailed balance through the choice of the acceptance ratios:
\begin{equation}
\frac{ P_{\mu\rightarrow\nu }}{ P_{\nu\rightarrow\mu }} = \frac{ A_{\mu\rightarrow\nu }}{ A_{\nu\rightarrow\mu } } = e^{-\beta ( E_\nu - E_\mu )}
\end{equation}

Suppose that $E_\mu < E_\nu $.
Then, $A ( \nu \rightarrow \mu ) > A ( \mu \rightarrow \nu ) $, and since only the acceptance ratio is fixed, we may freely set $A ( \nu \rightarrow \mu ) = 1$, which fixes $A ( \mu \rightarrow \nu ) = e^{-\beta ( E_\nu - E_\mu ) }$.
This choice maximizes the efficiency of the algorithm.
In short, we propose a random new state uniformly, and then we accept it with probability $A_{\mu\rightarrow \nu} = \min (1,  e^{-\beta ( E_\nu - E_\mu )})$.
After we reach the stationary distribution of the Markov process, we can use the states generated by our sampler to measure averages of physical quantities.
We consider this condition to be satisfied after a time $\tau_{\text{eq}}$, measured in steps of the algorithm.
When we consider a lattice model with a discrete set of states at each site $i = 1, 2, ..., N$, we say that a \emph{sweep} is completed whenever $N$ Monte Carlo steps are performed.
Thus, the number of \say{warm-up} sweeps is of order $W \sim \tau_{\text{eq}} / N$.

Before running a simulation, we need to decide how many sweeps we need to get an accurate estimate of the average.
The problem is that we need uncorrelated samples to average over, while the algorithm generates samples which are correlated in time.
To clarify, let us take the paradigmatic case of the Ising model, describing a magnetic solid with $N$ classical spins on a lattice.
If each spin takes on two values, say $\pm 1$, there are $2^N$ possible states, in total.
The Hamiltonian reads
\begin{equation}
H = - J \sum_{\left\langle i, j \right\rangle } s_i s_j - B \sum_i s_i ,
\end{equation}
where $\left\langle i, j \right\rangle$ means that $i, j $ are nearest neighbors on the lattice, and $B$ is an external magnetic field.

A simple strategy to sample configurations of the Ising model is single-spin-flip dynamics.
We start with a random configuration of the spins, and then propose new configurations at each step by flipping a single spin at a given site.
A sweep is completed after we propose a spin flip at every site on the lattice.

Consecutive configurations generated by this chain differ only slightly.
Thus, it takes some time for the system to reach a configuration which is significantly different from the initial one.
This characteristic time is called the correlation time $\tau_c$.
It can be estimated rigorously through the time-displaced self-correlation function associated to whatever observable is being measured.
A relevant quantity for the case of the Ising model is the magnetization per site:
$
m = \frac{1}{N} \sum_i s_i
$.
Its associated time-displaced self-correlator (Eq.(\ref{eq:selfCorr})) measures how correlated two magnetization measurements separated by a simulation time $t$ are.
\begin{equation}\label{eq:selfCorr}
\chi_m ( t ) = \int dt' \big( m ( t' ) - \left\langle m \right\rangle \big) \big( m ( t' + t ) - \left\langle m \right\rangle \big) = \int dt' \big( m ( t' ) m ( t' + t ) - \left\langle m \right\rangle^2 \big)
\end{equation}

The typical time-scale on which $\chi_m (t)$ falls off is a measure of the correlation time of the simulation.
In particular, at long times it falls off exponentially.
The definition of $\tau_c$ stems from this characteristic long-time behavior: $\chi_m (t) \sim e^{-t / \tau_c}$.
In practice, after waiting for $2\tau_c$, the measurements are virtually uncorrelated.
Let $A$ be the number of sweeps roughly  corresponding to $2\tau_c$ steps.
Then, if we make $S$ sweeps of the lattice during the simulation, the number of independent measurements (i.e. with $A$ sweeps between them) is 
$
M = \frac{S - W}{A}
$.

There are many ways to estimate $\tau_c$ from $\chi_m (t)$.
The simplest consists of making an exponential fit in a given range of times.
However, this might be unreliable since the estimate depends strongly on the chosen range.
An alternative is to compute the \say{integrated} correlation time:
\begin{equation}
\int_0^\infty dt \frac{\chi_m ( t ) }{\chi_m ( 0 ) } = \int_0^\infty dt e^{-t / \tau_c} = \tau_c  ,
\end{equation}
which is less sensitive, but not perfect since the assumption that \say{long-time} behavior has been reached is arbitrary and introduces an uncontrolled error.
Moreover, the very long-time behavior of the auto-correlation is rather noisy and must be excluded.

Using measured data for the magnetization at evenly-spaced times, we may construct the time-displaced auto-correlation function up to an unimportant constant, which does not affect the estimate of the correlation time:
\begin{equation}
\chi_m (t) = \frac{1}{ t_{\text{max}} - t } \sum_{t' = 0}^{t_{\text{max}} - t } m (t') m(t' + t) - \bigg(\frac{1}{ t_{\text{max}} - t } \sum_{t' = 0}^{t_{\text{max}} - t } m (t')\bigg) \bigg( \frac{1}{ t_{\text{max}} - t } \sum_{t' = 0}^{t_{\text{max}} - t } m(t' + t) \bigg) ,
\end{equation}
where $t_{\text{max}}$ is the total simulation time in MC steps.

One should be careful when using this expression at very long times.
As $t$ approaches $t_{\text{max}}$, the upper limit of the sums decreases, and the integration interval becomes narrower.
Since $m (t)$ fluctuates randomly at very long times, the statistical error associated to $\chi_m (t)$ becomes more prominent as $t$ approaches $t_{\text{max}}$.
This turns out not to be problematic since typical simulations run for many correlation times.
Thus, the tails of the auto-correlation may safely be neglected because the correlations will have already vanished, by definition.

To finish our discussion on the issue of computing the time-displaced correlator, we note that if we have a total of $N_s$ samples of, for instance, magnetization data, the complexity of computing $\chi_m$ is $\mathcal{O}(N_s^2)$.
It is possible to speed up this process by computing its Fourier transform $\tilde{\chi}_m(\omega)$, and inverting to recover $\chi_m (t)$.
This can be done via a standard \ac{FFT} algorithm in $\mathcal{O}(2 N_s \log N_s )$ flops.
To do this, we apply the following trick, based on time translation invariance:
\begin{equation}
\begin{split}
\tilde{\chi}_m ( \omega ) &= \int dt e^{i\omega t} \int dt' \bigg( m ( t' ) - \left\langle m \right\rangle \bigg) \bigg( m ( t' + t ) - \left\langle m \right\rangle \bigg) \\
&= \int dt \int dt' e^{-i\omega t'} \bigg( m ( t' ) - \left\langle m \right\rangle \bigg) e^{i\omega ( t' + t )} \bigg( m ( t' + t ) - \left\langle m \right\rangle \bigg) = \tilde{m}' (\omega) \tilde{m}' (- \omega) = | \tilde{m}' (\omega) |^2 ,
\end{split} 
\end{equation}
where $\tilde{m}' (\omega)$ is the Fourier transform of $m' (t) = m(t) - \left\langle m \right\rangle$\footnote{The only difference between $\tilde{m}' (\omega)$ and $\tilde{m} (\omega)$, is that $\tilde{m}' (0) = 0$, while $\tilde{m} (0) \neq 0$. Thus, one can also compute $\tilde{m} (\omega)$ and then set its $\omega = 0$ component to zero.}.

In practice, when implementing a MC algorithm, we take a measurement say every sweep (which can be less than a correlation time), and then compute the time-displaced correlator at the end of the simulation to estimate the correlation time.
How can we estimate the error in the mean of the $N_s$ correlated samples without knowing $\tau_c$ in advance?
Take again magnetization measurements.
Suppose your $N_s$ samples were  independent.
The standard deviation of their mean would be well known:
\begin{equation}\label{eq:errorUncorr}
\sigma = \sqrt{ \frac{ \frac{1}{N_s} \sum_{i=0}^{N_s} ( m_i - \overline{m} )^2 }{N_s - 1} } = \sqrt{ \frac{1}{N_s - 1} ( \overline{m^2} - \overline{m}^2 } )
\end{equation}

Intuitively, to get the correct result, we could simply replace $N_s$ by $M = \frac{S - W}{A}$, in the last step.
This is because the mean shouldn't change very much when including the correlated configurations with nearly the same magnetization.
However, the number of uncorrelated samples is certainly smaller than $N_s$, and can be estimated to be $M$ by auto-correlation studies.

As shown in \cite{muller-krumbhaar_dynamic_1973}, if the samples are separated by a time interval $\Delta t$,  the correct expression is
\begin{equation}\label{eq:errorCorr}
\sigma = \sqrt{ \frac{1 + 2\tau_c / \Delta t}{N_s - 1} ( \overline{m^2} - \overline{m}^2 )  } ,
\end{equation}
which reduces to Eq.(\ref{eq:errorUncorr})  when $\Delta t \gg \tau_c$, since in that case the samples are virtually  uncorrelated.
Also, we now have a rigorous justification for estimating the amount of time between uncorrelated samples as $2\tau_c$, since for much longer times, the samples become uncorrelated.

Often, we work with heavily correlated samples, so that instead we have $\Delta t \ll \tau_c$.
In this limit, the 1 in the numerator of Eq.(\ref{eq:errorCorr}) can be neglected, and noting that the number of sweeps between measurements corresponding to $\Delta t$ is $\Delta S = (S - W ) / N_s$, we have
\begin{equation}\label{eq:errorMC}
\sigma \approx \sqrt{ \frac{A}{S - W} ( \overline{m^2} - \overline{m}^2 )  }  ,
\end{equation}
the same result we would obtain by simply replacing $N_s$ by $M$.
What we found, in rigorous terms, was that the presence of many correlated samples does not significantly change the sample mean if $\Delta t \ll \tau_c$.
If we take enough correlated samples, their influence on the sample mean averages out.
Eq.(\ref{eq:errorMC}) has the advantage of being independent of $\Delta t$, which allows us to choose $\Delta t$ freely, without affecting the final error.
This is handy since it allows us to choose $\Delta t$ small so as not to lose data.

In practice, before we perform our Monte Carlo simulations, we do preliminary auto-correlation studies to ensure that we estimate the error in our measurements correctly.