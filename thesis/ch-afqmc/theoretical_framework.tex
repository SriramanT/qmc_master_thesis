\section{Theoretical framework}
\label{subsec:theoreticalFramework}

Auxiliary-field, or Determinant \acs{QMC} is a simulation method that is commonly used to simulate the Hubbard model, allowing one to capture the elusive effects of electron correlations, for example in the two-dimensional graphene-like nanostructures we are concerned with.

In general, the sign problem deems the algorithm exponentially complex in the size of the system and in inverse temperature, but it is possible to overcome this hurdle for a class of models, namely the Hubbard model at half filling ($\mu = 0$).
In fact, many interesting phenomena occur at half filling, for example magnetic ordering and the Mott metal-insulator transition.
The difficulty lies in computing the nearly vanishing average of a random variable $X$ with comparatively large variance, i.e. $\sigma_X / \left\langle X \right\rangle \gg 1$.

Ultimately, we seek a computable approximation of the projection operator $\mathcal{P}$ defined in equation (\ref{eq:projection}).
As we shall see, it is found by using a discrete Hubbard-Stratonovich transformation.
This transformation introduces an auxiliary field (consisting basically of Ising spins), and we use Monte Carlo to sample configurations from the distribution corresponding to this \emph{classical} configuration space.

\subsection{Trotter-Suzuki Decomposition}
\label{subsec:trotter}

In section \ref{sec:exactSolutions}, we found exact solutions for particular instances of the Hubbard model by finding a closed form for the partition function \cite{hou_numerical_2009}. When devising a numerical method, a good sanity check is to verify that it satisfactorily approximates the partition function since it is the quantity that can be used to obtain  any observable.
Computing the partition function of a quantum system in equilibrium

\begin{equation}\label{eq:partitionBeta}
Z_\beta = \text{Tr} \big( e^{-\beta \mathcal{H} } \big) = \sum_{\alpha} \left\langle \psi_\alpha | e^{-\beta \mathcal{H} } | \psi_\alpha \right\rangle
\end{equation}
is equivalent to studying its \emph{imaginary} time evolution.
The inverse temperature $\beta$ represents the imaginary time $\tau = it$, and $Z_\beta$ may be simply thought of as the wave function of the analogous quantum system at imaginary time $\beta$.
%To see this, recall that quantum states evolve according to
%
%\begin{equation}
%\left| \psi (t) \right\rangle = e^{-i \mathcal{H} t } \left| \psi (0) \right\rangle \iff \left| \psi (\tau) \right\rangle = e^{-\tau \mathcal{H} } \left| \psi (0) \right\rangle,
%\end{equation}
%
%Taking the scalar product with a position eigenstate $ \left\langle \bm x \right|$, we obtain $\psi (\bm x, \beta) = \left\langle \bm x | \psi (\beta) \right\rangle$.
%Using the closure relation $\int d\bm y \left| \bm y \right\rangle  \left\langle \bm y \right| = 1$, we get
%
%\begin{equation}
%\psi ( \bm x , \tau ) = \int d\bm y \left\langle \bm x | e^{-\tau \mathcal{H}} | \bm y \right\rangle \psi (\bm y, 0)
%\end{equation}
%
%The wave function at position $\bm x$ and time $\tau$ may be obtained by this equation as long as we know the wave function at $\tau = 0$, $\psi (\bm y, 0)$ for all points in space $\bm y$. The Green's function
%
%\begin{equation}
%G ( \bm x, \tau | \bm y, 0 ) \equiv \left\langle \bm x | e^{-\tau \mathcal{H}} | \bm y \right\rangle ,
%\end{equation}
%satisfies the Schr\"odinger equation, subject to the initial condition $\psi (\bm y, 0) = \delta (\bm y - \bm x )$. Thus, it corresponds to the probability of presence at $\bm x, \tau$ of a wave packet centered at $\bm y$ at $\tau = 0$. Thus, solving the Schr\"odinger equation is  analogous to solving the diffusion equation (that in turn one may obtain as the continuum limit of a random walk). We may write $G$ as a linear combination of the eigenstates of the Hamiltonian
%
%\begin{equation}
%G (\bm x, \tau | \bm y, 0) = \sum_\alpha \psi_\alpha^\star (\bm y) \psi_\alpha (\bm x) e^{-E_\alpha \tau}  ,
%\end{equation}
%so that
%
%\begin{equation}\label{eq:psiZ}
%\psi ( \bm x, \tau ) = \sum_\alpha \int d\bm y \, \psi_\alpha^\star (\bm y) \psi_\alpha (\bm x) e^{-E_\alpha \tau} \delta ( \bm y - \bm x ) = \sum_\alpha \psi_\alpha^\star (\bm x) \psi_\alpha (\bm x) e^{-E_\alpha \tau} = \sum_{\alpha} \left\langle \psi_\alpha | e^{-\tau \mathcal{H} } | \psi_\alpha \right\rangle
%\end{equation}
%where we immediately notice a striking similarity with equation (\ref{eq:z_asEigen}), by making $\psi (\bm x, \tau) \mapsto Z_\beta$.
In fact, for a zero temperature system, projective methods use this same principle to find the ground state.
In that case, the partition function strictly corresponds to the ground state wave function when $\tau \rightarrow \infty$ (in practice, one takes $\tau = \Theta$ large enough).
%As we can see from Eq.(\ref{eq:psiZ}), the higher energy states are exponentially suppressed in this limit, so that $\psi (\bm x, \tau) \rightarrow |\psi_0 (x)|^2 e^{-E_0 \tau}$.
%The initial condition does not even have to be $\psi ( \bm y, 0) = \delta ( \bm y - \bm x )$.
%More generally, as we saw for diffusion \acs{QMC}, we only require $\int d\bm y \, \psi_0^\star ( \bm y ) \psi ( \bm y, 0 ) = C \neq 0$, and we obtain $\psi (\bm x, \tau\rightarrow \infty) \rightarrow C \psi_0 (x) e^{-E_0 \tau}$.
 
Eq.(\ref{eq:partitionBeta}) is not very amenable to numerical computation since it contains an exponential of a sum of non-commuting operators $e^{-\beta (\mathcal{H}_K + \mathcal{H}_V)}$ as per Eq.(\ref{eq:def_energies}). 
The exponential is not factorizable and involves computing an infinite number of commutators containing these two operators, as per the Zassenhaus formula, valid for any two generic operators $X$ and $Y$\footnote{This is just the inverse of the well known Baker–Campbell–Hausdorff formula commonly used in quantum mechanics.}:

\begin{equation}\label{eq:zassenhaus}
e^{\delta (X+Y)}=e^{\delta X} e^{\delta Y} e^{-{\frac {\delta^{2}}{2}}[X,Y]} e^{{\frac {\delta^{3}}{6}}(2[Y,[X,Y]]+[X,[X,Y]])}  e^{{\frac {-\delta^{4}}{24}}([[[X,Y],X],X]+3[[[X,Y],X],Y]+3[[[X,Y],Y],Y])} \, ... , 
\end{equation}
where $\delta \in \mathbb{C}$ is an expansion parameter.
The Trotter-Suzuki decomposition leads to the sought approximate factorization that is used to approximate the partition function.
Dividing the imaginary time interval $[0, \beta ]$ into $L$ equal sub-intervals of width $\Delta \tau = \beta / L$, we obtain

\begin{equation}\label{eq:partBreak}
Z = \Tr \bigg( \prod_{l=0}^{L-1} e^{-\Delta\tau \mathcal{H} } \bigg) ,
\end{equation}
which is now a product of exponentials of operators multiplied by a constant that can be made small by increasing $L$, leading to an error that can be controlled.
Actually, this also arises naturally by writing the matrix elements of the projection operator $\mathcal{P}$ as path integrals:

\begin{equation}
\left\langle \psi | e^{-\beta \mathcal{H} } | \psi' \right\rangle = \sum_{\left| \psi_1 \right\rangle, \left| \psi_2 \right\rangle,..., \left| \psi_{L-1} \right\rangle }  \left\langle \psi | e^{-\Delta \tau \mathcal{H} } | \psi_1 \right\rangle \left\langle \psi_1 | e^{-\Delta \tau \mathcal{H} } | \psi_2 \right\rangle ... \left\langle \psi_{L - 1} | e^{-\Delta \tau \mathcal{H} } | \psi' \right\rangle 
\end{equation}

Then, the partition function only selects paths that are periodic in imaginary time:

\begin{equation}
Z = \text{Tr} \big( e^{-\beta \mathcal{H} } \big) = \sum_{\left| \psi_0 \right\rangle} \left\langle \psi_0 | e^{-\beta \mathcal{H} } | \psi_0 \right\rangle = \sum_{\{ \left| \psi_l \right\rangle \}} \prod_{l = 0}^{L - 1} \left\langle \psi_{l} | e^{-\Delta \tau \mathcal{H} } | \psi_{l+1} \right\rangle \delta_{0, L} = \Tr \bigg( \prod_{l=0}^{L-1} e^{-\Delta\tau \mathcal{H} } \bigg) ,
\end{equation}
where we have $\left| \psi_L \right\rangle = \left| \psi_0 \right\rangle$, and we  recover the result of Eq.(\ref{eq:partBreak}) by simply reorganizing the summations over $\{ \left| \psi_l \right\rangle \}$, so as to make appear closure relations, resulting in unit operators.

The \say{Trotter breakup} follows from truncating equation (\ref{eq:zassenhaus}), and keeping only the first order term in $\Delta \tau$.

\begin{equation}\label{eq:Z_propagator}
Z = \Tr \bigg( \prod_{l=1}^L e^{-\Delta\tau \mathcal{H}_K } e^{-\Delta\tau \mathcal{H}_V } \bigg) + \mathcal{O}(\Delta \tau^2) 
\end{equation}

The kinetic energy term is quadratic in the fermion operators, and is spin-independent and thus may be separated into spin up and spin down components

\begin{equation}
e^{-\Delta\tau \mathcal{H}_K} = e^{-\Delta\tau \mathcal{H}_{K_\uparrow}} e^{-\Delta\tau \mathcal{H}_{K_\downarrow}} ,
\end{equation}
where $\mathcal{H}_{K_\sigma} = -t \bm c_\sigma^\dagger \bm K  \bm c_\sigma$.

The potential energy term, however, is quartic. Surprisingly, it is possible to express it in quadratic form by introducing an extra degree of freedom, the so called \emph{Hubbard-Stratonovich (HS) field} $\bm h \equiv (h_i)_{i=1}^N$, in which each element is essentially an Ising spin. First, note that number operators on different sites commute, so that we have

\begin{equation}
e^{-\Delta\tau \mathcal{H}_V} = e^{-U \Delta\tau \sum_{i=1}^N (n_{i\uparrow} - 1/2 ) (n_{i\downarrow} - 1/2 )} = \prod_i e^{-U \Delta\tau (n_{i\uparrow} - 1/2 ) (n_{i\downarrow} - 1/2 )}
\end{equation}

Now we introduce the discrete Hubbard Stratonovich transformation for $U > 0$ that allows us to recast the equation above in terms of a non-interacting quadratic term $n_{i\uparrow} - n_{i\downarrow} $.

\begin{equation}\label{eq:discreteHS}
e^{-U \Delta\tau (n_{i\uparrow} - 1/2 ) (n_{i\downarrow} - 1/2 )} = c_U \sum_{h_i = \pm 1} e^{\nu h_i (n_{i\uparrow} - n_{i\downarrow} )},
\end{equation}
where $c_U = \frac{1}{2} e^{-\frac{U\Delta \tau}{4}}$ and $\nu = \text{arcosh} ( e^{\frac{U\Delta\tau}{2}})$.

To prove this identity, let us write down how the operators  $(n_{i\uparrow} - 1/2 ) (n_{i\downarrow} - 1/2 )$ and $(n_{i\uparrow} - n_{i\downarrow} )$ act on a state on a given site.

\begin{equation}
(n_{i\uparrow} - 1/2 ) (n_{i\downarrow} - 1/2 )
\begin{cases}
\left| \, \, \right\rangle = \frac{1}{4} \left| \, \, \right\rangle \\
\left| \uparrow \right\rangle = -\frac{1}{4} \left| \uparrow \right\rangle \\
\left| \downarrow \right\rangle = -\frac{1}{4} \left| \downarrow \right\rangle \\
\left| \uparrow \downarrow \right\rangle = \frac{1}{4} \left| \uparrow \downarrow \right\rangle
\end{cases} \quad
(n_{i\uparrow} - n_{i\downarrow} )
\begin{cases}
\left| \, \, \right\rangle = 0\left| \, \, \right\rangle \\
\left| \uparrow \right\rangle = \left| \uparrow \right\rangle \\
\left| \downarrow \right\rangle = \left| \downarrow \right\rangle \\
\left| \uparrow \downarrow \right\rangle = 0 \left| \uparrow \downarrow \right\rangle
\end{cases}
\end{equation}

Now we simply compare the action of the operators on the left hand side and on the right hand side of equation (\ref{eq:discreteHS}) and find the desired relation by defining

\begin{equation}
\cosh \nu =  \frac{e^\nu + e^{-\nu} }{2} \equiv e^{\frac{U\Delta \tau}{2}}
\end{equation}

\begin{equation}
\begin{split}
&e^{-U \Delta\tau (n_{i\uparrow} - 1/2 ) (n_{i\downarrow} - 1/2 )} \left| \psi \right\rangle = e^{-\frac{U\Delta \tau}{4}} \left| \psi \right\rangle \, , \left| \psi \right\rangle = \left| \, \, \right\rangle, \left| \uparrow \downarrow \right\rangle \\
&e^{-U \Delta\tau (n_{i\uparrow} - 1/2 ) (n_{i\downarrow} - 1/2 )} \left| \uparrow (\downarrow) \right\rangle = e^{\frac{U\Delta \tau}{4}} \left| \uparrow (\downarrow) \right\rangle \\
&c_U \sum_{h_i = \pm 1} e^{\nu h_i (n_{i\uparrow} - n_{i\downarrow} )} \left| \psi \right\rangle = e^{-\frac{U\Delta \tau}{4}} \left| \psi \right\rangle \, , \left| \psi \right\rangle = \left| \, \, \right\rangle, \left| \uparrow \downarrow \right\rangle \\
&c_U \sum_{h_i = \pm 1} e^{\nu h_i (n_{i\uparrow} - n_{i\downarrow} )} \left| \uparrow (\downarrow) \right\rangle= \frac{e^\nu + e^{-\nu}}{2} e^{-\frac{U\Delta \tau}{4}}  \left| \uparrow (\downarrow) \right\rangle
\end{split}
\end{equation}

Note that we require $U > 0$ so that there exists $\nu \in \mathbb{R}$ such that $\cosh \nu = e^{U\Delta \tau / 2}$. A similar reasoning could be made for $U < 0$. Additionaly, other transformations that recast other types of quartic terms in terms of quadratic ones exist, but we shall not need them in what follows \cite{hirsch_monte_1983}. The transformation we derived is the one we will use throughout.

We have now made progress. At the expense of introducing an extra $N$-dimensional HS-field $\bm h$, we obtained an \emph{exact} representation of the quartic term in terms of quadratic terms \cite{hou_numerical_2009}.

\begin{equation} 
 e^{-\Delta\tau \mathcal{H}_V} = \prod_{i=1}^N \bigg( c_U \sum_{h_i = \pm 1} e^{\nu h_i ( n_{i\uparrow} - n_{i\downarrow} )} \bigg),
\end{equation} 
which can be manipulated to arrive at a more compact form.

\begin{equation}\label{eq:exp_quartic}
\begin{split}
e^{-\Delta\tau \mathcal{H}_V} &=  (c_U)^N \sum_{h_i = \pm 1} e^{\nu h_i ( n_{1\uparrow} - n_{1\downarrow} )} \sum_{h_i = \pm 1} e^{\nu h_i ( n_{2\uparrow} - n_{2\downarrow} )} ... \sum_{h_i = \pm 1} e^{\nu h_i ( n_{N\uparrow} - n_{N\downarrow} )} \\
&= (c_U)^N \sum_{h_i = \pm 1} e^{\sum_{i=1}^N [(\nu h_i ( n_{i\uparrow} - n_{i\downarrow} ) ]} \equiv (c_U)^N \text{Tr}_h e^{\sum_{i=1}^N [(\nu h_i ( n_{i\uparrow} - n_{i\downarrow} ) ]} \\
&= (c_U)^N \text{Tr}_h e^{\sum_{i=1}^N \nu h_i n_{i\uparrow}} e^{-\sum_{i=1}^N \nu h_i n_{i\uparrow}} = (c_U)^N \text{Tr}_h ( e^{\mathcal{H}_{V_\uparrow}} e^{\mathcal{H}_{V_\downarrow}} ) ,
\end{split}
\end{equation}
where the spin up and spin down operators $\mathcal{H}_{V_\sigma}$ are defined as follows

\begin{equation}
\mathcal{H}_{V\sigma} = \sum_{i=1}^N \nu h_i n_{i\sigma} = \sigma \nu \bm c_\sigma^\dagger \bm V(\bm h) \bm c_\sigma,
\end{equation}
with $\bm V(\bm h)$ being simply the HS-field put into a diagonal $N\times N$ matrix: $\bm V(\bm h) \equiv \text{diag}(h_1, h_2, ..., h_N)$.

For each imaginary time slice $l$, we may define a HS-field $\bm h_l$, which in turn specifies $\bm V_l$ and $\mathcal{H}_{V_\sigma}^l$.
We may now replace the result of equation (\ref{eq:exp_quartic}) in equation (\ref{eq:Z_propagator}), and exchange the traces to obtain

\begin{equation}\label{eq:Z_quadratic}
Z_h = (c_U)^{NL} \text{Tr}_{\bm h} \Tr \bigg[ \prod_{l=0}^{L-1} \underbrace{\bigg( e^{-\Delta\tau  \mathcal{H}_{K_\uparrow}} e^{\mathcal{H}_{V_\uparrow}^l} \bigg)}_{B_{l, \uparrow}(\bm h_l)} \underbrace{\bigg( e^{-\Delta\tau  \mathcal{H}_{K_\downarrow}} e^{\mathcal{H}_{V_\downarrow}^l} \bigg)}_{B_{l, \downarrow}(\bm h_l)} \bigg],
\end{equation}
where all operators are now quadratic in the fermion operators:

\begin{equation}
\mathcal{H}_{K_\sigma} = - t \bm c_\sigma^\dagger \bm K \bm c_\sigma \quad \mathcal{H}_{V_\sigma}^l = \sigma \nu \bm c_\sigma^\dagger \bm V_l (\bm h_l) \bm c_\sigma
\end{equation}
for $\sigma = \pm 1$ and $\bm V_l ( \bm h_l ) = \text{diag} ( h_{l, 1} , h_{l, 2}, ... , h_{l, N} )$.

Furthermore, we have defined the $\bm B$-matrices

\begin{equation}
\bm B_{l, \sigma} ( \bm h_l ) = e^{t \Delta \tau \bm K} e^{\sigma \nu \bm V_l (\bm h_l)}
\end{equation}

Note that the argument of the first exponential is positive since $\bm K$ is defined so that its entries are 0's and 1's; otherwise (defining $\bm K$ with 0's and $-1$'s) it would be negative.

The problem of computing the partition has been reduced to computing the trace of a product of exponentials of quadratic forms. Thus, we may still rewrite equation (\ref{eq:Z_quadratic}) by making use of the following identity.

Let $\mathcal{H}_l$ be quadratic forms of the fermion operators:

\begin{equation}
\mathcal{H}_l = c_i^\dagger (H_l)_{ij} c_j,
\end{equation}
where the summation is implied, and where $H_l$ are real matrices.
Then, the following identity holds

\begin{equation}\label{eq:quadraticIdentity}
\Tr \big[ e^{-\mathcal{H}_1 } e^{-\mathcal{H}_2 } ... e^{-\mathcal{H}_L } \big] = \text{det} ( \bm I + e^{-H_L} e^{-H_{L-1}} ... e^{-H_1} )
\end{equation}

For simplicity, in appendix \ref{ap:theoAFQMC}, we present the proof for a simpler case, corresponding to a single $\bm B$-matrix, i.e. a product of exponentials of two quadratic operators \cite{hirsch_two-dimensional_1985}.
It could then be easily extended to the more general case (see \cite{hanke_electronic_nodate}, chapter 4).

When applied to our problem, Eq.(\ref{eq:quadraticIdentity}) essentially makes the computation of the trace possible! Note that if we were to compute it na\"ively, we would soon run out of computer memory.
The dimension of the Hilbert space of the Hubbard model is exponential in the number of sites N (actually $4^N$). The determinant can be calculated in $\mathcal{O}(N^3)$ flops for a matrix whose size is polynomial in $N$. 
Thus, the computable form of the partition function (\ref{eq:Z_quadratic}) is

\begin{equation}\label{eq:effectiveDensityMatrix}
Z_{\bm h} =  \Tr_{\bm h} \bigg[ (c_U)^{NL} \text{det} [ \bm M_\uparrow (\bm h)] \text{det} [  \bm M_\downarrow (\bm h) ] \bigg] = \sum_{\{ \bm h \} } P ( \bm h ) \equiv \sum_c p_c
\end{equation}
where the fermion matrices $\bm M_\sigma$ are defined in terms of the $\bm B$-matrices that depend on the HS-field $\bm h$:

\begin{equation}
\bm M_\sigma (\bm h) = \bm I + \bm B_{L,\sigma} ( \bm h_L) \bm B_{L-1,\sigma} ( \bm h_{L-1}) ... \bm B_{1\sigma} ( \bm h_1) = \bm I + \prod_{l= L -1}^0 \bm B_{l,\sigma} ( \bm h_l )
\end{equation}

By casting the fermionic trace as a product of determinants, we obtained the computable approximation of the distribution operator $\mathcal{P}$ corresponding to $Z_{\beta}$ as advertised in Eq.(\ref{eq:Zsign}).

\begin{equation}
P(\bm h) = \frac{A}{Z_{\bm h}} \det [ \bm M_{\uparrow}(\bm h) ] \det [ \bm M_{\downarrow}(\bm h) ] ,
\end{equation}
where $A = (c_U)^{NL}$ is a normalization constant.
This is now a distribution function over configurations $c$ of the field $\bm h$ since the problem is \say{classical} (the quotes serve to emphasize that $p_c$ can be negative)!

For the particular case of no interactions $U = 0$, we have that $\nu = 0$, and $\bm M_\sigma (\bm h)$ are independent of the HS-field. 
The Trotter-Suzuki approximation then becomes exact and the Hubbard Hamiltonian may be simulated exactly after evaluating $\bm M_\sigma (\bm h)$ a single time.
No updates are required.

We mapped a quantum problem to a \say{classical} problem with an extra imaginary-time dimension.
Note that the size of the state space might have been increased to $2^{NL}$ (assuming that $L > 2$), and even if it didn't, it still remains exponential.
However, it can be now be probed more easily: while we might have increased the number of possible configurations by introducing the mapping, we arrived at a form which is tractable by a standard Monte Carlo method, as described in the previous section.
This is because we may now efficiently navigate through the exponentially large state space of the system using importance sampling.

Schematically, the degrees of freedom of the quantum problem correspond to the $i$-indices of the $c$-operators.
In our formulation, an additional imaginary time slice index $l$ was introduced, leading to a mapping that is not specific to the Hubbard model, but that actually applies very generally for any quantum system.

\subsection{Monte Carlo sampling of the HS-field}
\label{subsec:mc_hs}

The computational problem is now that of sampling configurations of the $\bm h$ field drawn from the distribution $P(\bm h)$ using \emph{Classical} Monte Carlo.
It remains to choose a dynamics and a sampling scheme. The simplest strategy to change from a configuration $\bm h$ to a new one $\bm h'$ is single spin-flip dynamics. We choose a random point $(l, i)$, and we flip the spin at that space-time  \say{site}:
$
h_{l, i}' = - h_{l, i},
$
keeping all others unchanged.
The most common scheme to ensure that the distribution of the accepted sample is $P(\bm h)$ is the Metropolis-Hastings algorithm.
After the warm-up steps, i.e. after we ensure that we are correctly sampling from the required distribution, we may perform measurements.

\begin{algorithm}
\caption{Auxiliary Field Quantum Monte Carlo Sampling Scheme}
\label{afqmcSampling}
\begin{algorithmic}[5]
  \STATE Initialize HS field $\bm h$  \\
  \STATE Initialize hoppings $\bm K$  \\
  \STATE  $(h_{l, i}) = (\pm 1)_{l=1, i = 1}^{L, N}$
  \STATE $(l, i) \leftarrow (1, 1)$
  \FOR{$\text{step} = 1$ to $S$}
  \STATE \footnotesize{Propose new configuration by flipping a spin} \\ \normalsize{$h_{l, i}' = - h_{l, i}$} 
  \STATE \footnotesize{Compute the acceptance ratio $a_{l, i}$} \\
  \normalsize{$\frac{\text{det}[\bm M_\uparrow (\bm h')]\text{det}[\bm M_\downarrow (\bm h')]}{\text{det}[\bm M_\uparrow (\bm h)]\text{det}[\bm M_\downarrow (\bm h)]}$}
  \STATE \textbf{\normalsize{Metropolis step}}
  \STATE \footnotesize{Draw random number $r \in [0,1]$}
  \IF{$r \le \min(1, a_{l, i})$}
  \STATE $\bm h = \bm h'$
  \ELSE
  \STATE $\bm h = \bm h$
  \ENDIF
  \STATE Next site
  \IF{$i < N$}
  \STATE $l = l$ , $i = i +1 $
  \ELSE
  \IF {$l < L$}
  \STATE $l = l+1$ , $i = 1 $
  \ENDIF
  \IF {$l = L$}
  \STATE $l = 1$ , $i=1$
  \ENDIF
  \ENDIF
  \ENDFOR
\end{algorithmic}
\end{algorithm}

The Metropolis acceptance/rejection scheme leads to a rank-one update of the matrices $\bm M_\sigma (\bm h)$, which affords an efficient evaluation of the acceptance ratio $a_{l, i}$ \cite{hou_numerical_2009} (see appendix \ref{ap:theoAFQMC}).

\subsection{Making measurements}

In QMC simulations, physical observables are extracted by measuring them directly over the course of the sampling of the  configuration space. The single-particle (equal time) Green's Function is useful to obtain quantities such as density and kinetic energy. It turns out that it is simply the inverse of the $\bm M$-matrix that we already compute to obtain the acceptance ratio at each step.

\begin{equation}
G_{ij}^\sigma = \left\langle c_{i,\sigma} c_{j,\sigma}^\dagger \right\rangle_{\bm h} = \bigg( \bm M_\sigma^{-1} (\bm h) \bigg)_{ij} = \bigg( [\bm I + \prod_{l= L -1}^0 \bm B_{l,\sigma} ( \bm h_l ) ]^{-1} \bigg)_{ij}
\end{equation}

The equal time Green's function is a fermion average for a given HS-field configuration \cite{santos_introduction_2003}.

The electron density may be obtained from the Green function

\begin{equation}
\rho_{i, \sigma} = \left\langle c_{i,\sigma}^\dagger c_{i,\sigma} \right\rangle = 1 - \left\langle c_{i,\sigma} c_{i,\sigma}^\dagger \right\rangle = 1 - G_{ii}^\sigma ,
\end{equation}

It is natural to think of averaging this over the lattice.
This is justified by the fact that the Hubbard Hamiltonian is translationally invariant.
Thus, $\rho_{i\sigma}$ should be independent of the spatial site.
This statement is strict when exactly solving the model, but it becomes only approximate, i.e. valid only on average in our simulations.
Thus, we take the average

\begin{equation}
\rho = \frac{1}{N} \sum_\sigma \sum_{i=1}^N \rho_{i, \sigma} = 2 - \frac{1}{N} \sum_\sigma \sum_{i=1}^N G_{ii}^\sigma
\end{equation}
in an attempt to reduce statistical errors.

One must pay attention to the symmetry of the model at hand, since a similar model for a disordered system including randomness would not be translationally invariant anymore.
Moreover, it is implicit that $\rho_{i\sigma}$ is already averaged over the HS-field configurations that were sampled through the simulation.

The average kinetic energy is similarly obtained.

\begin{equation}
\left\langle \mathcal{H}_K \right\rangle = - t  \sum_{\left\langle i, j \right\rangle , \sigma} \left\langle ( c_{i\sigma}^\dagger c_{j\sigma} + c_{j\sigma}^\dagger c_{i\sigma} ) \right\rangle = t \sum_{\left\langle i, j \right\rangle , \sigma} ( G_{ij}^\sigma + G_{ji}^\sigma ) = t \sum_{ i, j , \sigma} K_{ij} ( G_{ij}^\sigma + G_{ji}^\sigma )  ,
\end{equation}
where the minus sign is due to the switching of the order of the operators bringing the $c^\dagger$ to the right.

\subsection{Correlation functions}

One of the most important goals of QMC simulations is to inspect the system for order of various types, and to find  associated phase transitions. This is done by computing correlation functions $C (j) $, measuring how correlated two sites separated by a distance $j$ are.

\begin{equation}
C(j) = \big\langle \mathcal{O}_{i+j} \mathcal{O}_{i}^\dagger \big\rangle - \langle \mathcal{O}_{i+j} \big\rangle\big\langle\mathcal{O}_{i}^\dagger \big\rangle ,
\end{equation}
where $\mathcal{O}$ is an operator corresponding to the order parameter of the phase transition. For example, we might be looking for magnetic order, in which case the relevant operators are $S^z_i$, i.e. $\mathcal{O}_i = n_{i\uparrow} - n_{i\downarrow} \, , \, \mathcal{O}_i^\dagger = n_{i\uparrow} - n_{i\downarrow}$, or superconductivity, where we would like to measure correlations in fermion pair formation: $\mathcal{O}_i = c_{i\downarrow} c_{i\uparrow} \, , \, \mathcal{O}_i^\dagger = c_{i\uparrow}^\dagger c_{i\downarrow}^\dagger$.

In general, we expect a high temperature disordered phase, for which correlations decay exponentially $C(j) \propto e^{-j/\xi}$, where $\xi$ is a characteristic length called the correlation length. At some point, there can be a transition to a low temperature phase, where $C(j) \propto m^2$, where $m$ is the order parameter for the transition. Right at the transition, that is at $T = T_c$, there might be singular behavior. In continuous phase transitions, the correlation length diverges $\xi \propto (T-T_c)^{-\nu}$, and the correlations decay slower (in fact algebraically): $C(j) \propto j^{-\eta}$, in an intermediate behavior between exponential decay and a constant. The \emph{critical} exponents $\nu$, and $\eta$ are characteristic of the transition, or more accurately, of the universality class it belongs to.

The behavior of all these quantities on finite lattices does not precisely correspond to the infinite system behavior. The tails of the functions, i.e. the $j\rightarrow \infty$ limit is not well captured. Finite-size scaling is a method to improve on these predictions.

To evaluate correlation functions we use Wick's theorem. Expectations of more than two fermion creation and annihilation operators reduce to products of expectations of pairs of creation and annihilation operators. For example, for spin order in $x/y$ direction:

\begin{equation}
\big\langle C(j) \big\rangle = \big\langle c_{i+j, \downarrow}^\dagger c_{i+j, \uparrow} c_{i, \uparrow}^\dagger c_{i, \downarrow} \big\rangle = G_{i+j, i}^\uparrow G_{i, i + j}^\downarrow
\end{equation}

How would one measure a correlation function experimentally? Fortunately, there is a quantity that is easy to measure called structure factor, which is just the Fourier transform of the correlation function

\begin{equation}
S(\bm q) = \sum_j e^{i\bm q \cdot \bm R_j} C(j) 
\end{equation}

The accuracy of QMC simulations can be evaluated by comparing the results for the Fourier transformed correlation functions with the corresponding experimentally measured structure factors.